{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".. index:: regression, wine\n",
    "\n",
    "# Use a regression to predict wine quality\n",
    "\n",
    "\n",
    "I will use `wine quality data set <https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv>`_\n",
    "from the `UCI Machine Learning Repository <https://archive.ics.uci.edu/ml/datasets.html>`_.  \n",
    "The dataset contains quality ratings (labels) for a 1599 red wine samples. \n",
    "The features are the wines' physical and chemical properties (11 predictors). \n",
    "We want to use these properties to predict the quality of the wine. \n",
    "The experiment is shown below and can be found in the \n",
    "`Cortana Intelligence Gallery <https://gallery.cortanaintelligence.com/Experiment/Predict-Wine-Quality-Classification-10>`_\n",
    "\n",
    "*Sources:* \n",
    "\n",
    "- `Predicting Wine Quality with Azure ML and R <http://blog.revolutionanalytics.com/2016/04/predicting-wine-quality.html>`_\n",
    "- `Predicting Wine\n",
    "  Quality <https://github.com/shaheeng/ClassificationModelEvaluation/blob/master/PredictWineQuality_RevBlog3/Predicting%20Wine%20Quality%20-%20Shaheen.ipynb>`_\n",
    "  (notebook)\n",
    "  \n",
    "*Contents:*\n",
    "\n",
    "Processing the data\n",
    "===================\n",
    "\n",
    "Let's start with collecting and preparing the data.\n",
    "We save them in a single file in order to avoid downloading them\n",
    "many times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"wines_backup.csv\"):\n",
    "    # if not exist, we create wines.csv which combines red and white wines into a single file\n",
    "    columns = [\"facidity\", \"vacidity\", \"citric\", \"sugar\", \"chlorides\", \"fsulfur\", \"tsulfur\", \"density\",\n",
    "               \"pH\", \"sulphates\", \"alcohol\", \"quality\"]\n",
    "    red = pandas.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "                         names=columns, sep=\";\", skiprows=1)\n",
    "    white = pandas.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "                         names=columns, sep=\";\", skiprows=1)\n",
    "    red[\"color\"] = \"red\"\n",
    "    white[\"color\"] = \"white\"\n",
    "    wines = pandas.concat([white, red])\n",
    "    wines.to_csv(\"wines_backup.csv\", sep=\"\\t\", index=False)\n",
    "else:\n",
    "    wines = pandas.read_csv(\"wines_backup.csv\", sep=\"\\t\")\n",
    "    \n",
    "print(wines.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the quality of the wines.\n",
    "Let's see how this variable is distributed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "wines[\"quality\"].hist(bins=7, ax=ax)\n",
    "ax.set_xlabel(\"quality\")\n",
    "ax.set_ylabel(\"# wines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any differance between red and white wines?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = wines[wines.color==\"red\"][\"quality\"]\n",
    "white = wines[wines.color==\"white\"][\"quality\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist([red, white], label=[\"red\", \"white\"], alpha=0.5,\n",
    "        histtype='bar', bins=7, color=[\"red\", \"green\"])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"quality\")\n",
    "ax.set_ylabel(\"# wines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more white wines and more high quality white wines.\n",
    "Let's see if the quality is correlated to the alcohol degree?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(x=wines.alcohol, y=wines.quality)\n",
    "ax.set_xlabel(\"alcohol\")\n",
    "ax.set_ylabel(\"quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite difficult to see don't you think?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "wines.plot.hexbin(x='alcohol', y='quality', ax=ax, gridsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alcohol does not explain the quality all by itself.\n",
    "\n",
    "Predict the quality of the wine\n",
    "===============================\n",
    "\n",
    "The quality is a mark between 1 and 9.\n",
    "We use a fast tree regression to predict it.\n",
    "But before anything starts, we need to split the dataset\n",
    "into train and test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "wines_train, wines_test = train_test_split(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we train. We drop the color which is a non numerical\n",
    "features. We will add it later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsoftml import rx_fast_trees\n",
    "cols = wines.columns.drop([\"quality\", \"color\"])\n",
    "model = rx_fast_trees(\"quality ~\" + \"+\".join(cols), data=wines_train, method=\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsoftml import rx_predict\n",
    "pred = rx_predict(model, wines_test, extra_vars_to_write=[\"quality\"])\n",
    "print(pred.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'Score' is the prediction.\n",
    "We estimate its quality with the metric `R2 <http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html>`_\n",
    "and we plot them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(pred.quality, pred.Score)\n",
    "print(\"R2=\", r2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(x=pred.quality, y=pred.Score)\n",
    "ax.set_xlabel(\"quality\")\n",
    "ax.set_ylabel(\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not easy to read.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "pred.plot.hexbin(x='quality', y='Score', ax=ax, gridsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be doing a relatively good job to predict\n",
    "marks 5, 6, 7. As we saw with the distribution, \n",
    "the dataset contain many examples for these marks\n",
    "and not many for the others.\n",
    "\n",
    ".. index:: feature importance\n",
    "\n",
    "Feature Importance\n",
    "==================\n",
    "\n",
    "Let's see which variables contribute the most to the prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = [(k, v) for k, v in model.summary_[\"keyValuePairs\"].items()]\n",
    "\n",
    "import numpy\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ind = numpy.arange(len(feature_importance))\n",
    "ax.barh(ind, [f[1] for f in feature_importance], 0.35)\n",
    "ax.set_yticks(ind + 0.35 / 2)\n",
    "ax.set_yticklabels([f[0] for f in feature_importance])\n",
    "ax.set_title(\"Feature importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alcohol is the dominant feature but the others still play\n",
    "an important part in the prediction.\n",
    "\n",
    "Does the color help?\n",
    "====================\n",
    "\n",
    "To answer that question, we need to add the wine color\n",
    "as a new feature. Because it is a categorical feature, we \n",
    "need to convert it into a numerical one.\n",
    "We use the transform :epkg:`microsoftml:categorical`\n",
    "to convert column *color* into *color_num*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsoftml import categorical\n",
    "cols = list(wines.columns.drop([\"quality\", \"color\"]))  # We still drop column color.\n",
    "cols.append(\"color_num\")  # But we add the new one.\n",
    "model = rx_fast_trees(\"quality ~\" + \"+\".join(cols), data=wines_train, method=\"regression\",\n",
    "                      ml_transforms=[categorical(cols=dict(color_num=\"color\"))])\n",
    "pred = rx_predict(model, wines_test, extra_vars_to_write=[\"quality\"])\n",
    "r2_color = r2_score(pred.quality, pred.Score)\n",
    "print(\"R2 with colors=\", r2_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is not better. Let's confirm that with \n",
    "the feature importances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = [(k, v) for k, v in model.summary_[\"keyValuePairs\"].items()]\n",
    "\n",
    "import numpy\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ind = numpy.arange(len(feature_importance))\n",
    "ax.barh(ind, [f[1] for f in feature_importance], 0.35)\n",
    "ax.set_yticks(ind + 0.35 / 2)\n",
    "ax.set_yticklabels([f[0] for f in feature_importance])\n",
    "ax.set_title(\"Feature importances with colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color does not help or we can say that the prediction model\n",
    "is color blind.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
