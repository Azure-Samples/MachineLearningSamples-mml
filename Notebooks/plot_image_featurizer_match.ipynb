{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".. index:: image, similarity\n",
    "\n",
    "# Image Featurization Applied to Find Similar Images\n",
    "\n",
    "\n",
    "Here is the scenario this sample addresses: You have a catalog \n",
    "of images in a repository. When you get a new image, you want \n",
    "to find the image from your catalog that most closely matches \n",
    "this new image.\n",
    "The procedure for finding the best match has the following steps:\n",
    "    \n",
    "- Locate the images in the catalogue and get their feature vectors.\n",
    "- Locate the new image and get its feature vector.\n",
    "- Find out which image or set of images from the catalog has the \n",
    "  smallest \"distance\" from the new image. There are a number of \n",
    "  ways to calculate this distance. A simple one is the Euclidean \n",
    "  distance, which we use in this sample.\n",
    "\n",
    "In this sample, our intial catalog consists a set of pictures of fish and helicopters.\n",
    "First, create a dataframe with the locations of these images:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    root = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    # __file__ does not exist in a notebook\n",
    "    root = \".\"\n",
    "\n",
    "# An absolute path must be used if the current folder\n",
    "# is not the script's one.\n",
    "image_location = os.path.abspath(os.path.join(root, \"Data\", \"Pictures\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify paths to the images we want to featurize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for im in [\"Fish/Fish1.jpg\", \"Fish/Fish2.jpg\", \n",
    "           \"Helicopter/Helicopter1.jpg\", \"Helicopter/Helicopter2.jpg\"]:\n",
    "    images.append(os.path.join(image_location, im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the image to see what they look like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "for i, im in enumerate(images):\n",
    "    ax[i // 2, i % 2].imshow(Image.open(im))\n",
    "\n",
    "################\n",
    "# Setup a dataframe with the path to the image.\n",
    "\n",
    "import pandas\n",
    "image_df = pandas.DataFrame(data=dict(image=images))\n",
    "print(image_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, get the corresponding feature vectors for each \n",
    "of the catalog images into a dataframe.\n",
    "We follow the process mentioned at `l-imgfeat`.\n",
    "We load, resize, convert into pixels and finally build\n",
    "vectors from images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsoftml import rx_featurize, load_image, resize_image, extract_pixels, featurize_image\n",
    "image_vector = rx_featurize(data=image_df, ml_transforms=[\n",
    "    load_image(cols=dict(Features=\"image\")),\n",
    "    resize_image(cols=\"Features\", width=227, height=227),\n",
    "    extract_pixels(cols=\"Features\"),\n",
    "    featurize_image(cols=\"Features\", dnn_model=\"Alexnet\")])\n",
    "\n",
    "print(image_vector.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, create a dataframe with the location of \n",
    "the new image to match and get its feature vector into a dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_match = []\n",
    "for im in [\"Fish/Fish4.jpg\"]:\n",
    "    images_match.append(os.path.join(image_location, im))\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(Image.open(images_match[0]))\n",
    "\n",
    "image_match_df = pandas.DataFrame(data=dict(image=images_match))\n",
    "\n",
    "image_match_vectors = rx_featurize(data=image_match_df, ml_transforms=[\n",
    "    load_image(cols=dict(Features=\"image\")),\n",
    "    resize_image(cols=\"Features\", width=227, height=227),\n",
    "    extract_pixels(cols=\"Features\"),\n",
    "    featurize_image(cols=\"Features\", dnn_model=\"Alexnet\")])\n",
    "    \n",
    "print(image_match_vectors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, compare the new image with the images in the \n",
    "catalogue to find the best match. \n",
    "We have 2 sets of feature vectors: \n",
    "\n",
    "- ``image_vectors`` contains the feature vectors for the catalog images; \n",
    "- ``image_match_vectors`` contains the feature vector of the new image to be compared.\n",
    "\n",
    "The best match is defined (for our purposes) as the image pair \n",
    "with the least Euclidean distance between their image feature \n",
    "vectors where one of the feature vectors is for the new image. \n",
    "We implement these calculations using \n",
    "`cdist <https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html#scipy.spatial.distance.cdist>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matimg = image_vector.drop(\"image\", axis=1).as_matrix()\n",
    "matmat = image_match_vectors.drop(\"image\", axis=1).as_matrix()\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "distance = cdist(matimg, matmat)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains 4 values corresponding to the Euclidian\n",
    "distance between the new image and the first four images\n",
    "we used as reference.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The actual values can change slightly depending on the machine \n",
    "      used to run the code, but the order relations between the distance \n",
    "      values should be invarient.</p></div>\n",
    "\n",
    "And the winner is...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = distance.argmin()\n",
    "print(arg)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(Image.open(images[arg]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
